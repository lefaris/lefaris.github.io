
@Article{s25020370,
AUTHOR = {Ervin, Lauren and Eastepp, Max and McVicker, Mason and Ricks, Kenneth},
TITLE = {Evaluation of Semantic Segmentation Performance for a Multimodal Roadside Vehicle Detection System on the Edge},
JOURNAL = {Sensors},
VOLUME = {25},
YEAR = {2025},
NUMBER = {2},
ARTICLE-NUMBER = {370},
URL = {https://www.mdpi.com/1424-8220/25/2/370},
PubMedID = {39860740},
ISSN = {1424-8220},
ABSTRACT = {Discretely monitoring traffic systems and tracking payloads on vehicle targets can be challenging when traversal occurs off main roads where overhead traffic cameras are not present. This work proposes a portable roadside vehicle detection system as part of a solution for tracking traffic along any path. Training semantic segmentation networks to automatically detect specific types of vehicles while ignoring others will allow the user to track payloads present only on certain vehicles of interest, such as train cars or semi-trucks. Different vision sensors offer varying advantages for detecting targets in changing environments and weather conditions. To analyze the benefits of both, corresponding LiDAR and camera data were collected at multiple roadside sites and then trained on separate semantic segmentation networks for object detection. A custom CNN architecture was built to handle highly asymmetric LiDAR data, and a network inspired by DeepLabV3+ was used for camera data. The performance of both networks was evaluated, and showed comparable accuracy. Inferences run on embedded platforms showed real-time execution matching the performance on the training hardware for edge deployments anywhere. Both camera and LiDAR semantic segmentation networks were successful in identifying vehicles of interest from the proposed viewpoint. These highly accurate vehicle detection networks can pair with a tracking mechanism to establish a non-intrusive roadside detection system.},
DOI = {10.3390/s25020370}
}



